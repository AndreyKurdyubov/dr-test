import os
import streamlit as st
from streamlit import session_state as ss
import requests
from bs4 import BeautifulSoup
from sqlalchemy import create_engine, text
from datetime import datetime
import pandas as pd  
from zoneinfo import ZoneInfo
import glob
import re
from utils import find_db_files, convert_date_string
from utils import menu, authentication

#####################################################################################################################################################
# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
#####################################################################################################################################################

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(page_title='Ducküå≥Run', page_icon=':running:')

menu()
authenticator, name, authentication_status, username = authentication()
# if 'session_start' not in ss:
#     ss.session_start = 1
#     st.rerun()

db_name = find_db_files()

# –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
image_path = 'logo.jpg'
num_runs = 3  # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–≥—Ä—É–∂–∞–µ–º—ã—Ö –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤

# –í—Å—Ç–∞–≤–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
st.image(image_path, caption='')

# –°–∫—Ä—ã—Ç–∏–µ —Ñ—É—Ç–µ—Ä–∞ –∏ –º–µ–Ω—é
hide_streamlit_style = """
            <style>
            MainMenu {visibility: hidden;}
            footer {visibility: hidden;}
            </style>
            """
st.markdown(hide_streamlit_style, unsafe_allow_html=True)
time_out = 5
run_data = ss.get('run_data')
now_t = ss.get('now_t')
all_participant_data = ss.get('all_participant_data')
all_volunteer_data = ss.get('all_volunteer_data')

# –ó–∞–≥–æ–ª–æ–≤–æ–∫
# st.header('–ë–∞–∑–∞ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ 5–í–µ—Ä—Å—Ç –ü–µ—Ç–µ—Ä–≥–æ—Ñ –ê–ª–µ–∫—Å–∞–Ω–¥—Ä–∏–π—Å–∫–∏–π')

st.divider()

col1, col2 = st.columns(2)

with col1:
    if username in ['host', 'org']:
        if db_name:
            db_name = 'sqlite:///' + db_name[-1]
            st.success(f'–ù–∞–π–¥–µ–Ω–∞ –ë–î –æ—Ç {convert_date_string(db_name[10:-3])}')
            engine = create_engine(db_name)
            
            st.write('*–°–ø–∏—Å–æ–∫ —Å—Ç—Ä–∞–Ω–∏—Ü:*')
            # st.page_link("pages_dir\main_table.py", label="–ë–∞–∑–∞ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤")
            st.markdown('''
            - [–ö–ª—É–±—ã –∏ —Ä–µ–∫–æ—Ä–¥—ã](records_table)
            - [–ü–æ—Å–ª–µ–¥–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã](last_results)        
            ''')
        else:
            st.write('–ë–∞–∑–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')

    # if username in ['host']:
    #     st.markdown('''
    #     - [–ë–∞–∑–∞ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤](main_table)
    #     - [–ö–ª—É–±—ã –∏ —Ä–µ–∫–æ—Ä–¥—ã](records_table)
    #     - [–ü–æ—á—Ç–∏ –≤ –∫–ª—É–±–µ](almost_club)
    #     - [–ö–∞–∫–∏–µ –ª—é–¥–∏!](hellothere)
    #     - [–ü–æ—Å–ª–µ–¥–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã](last_results)
    #     - [–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ](update)           
    #     ''')
    # else:
    #     st.markdown('''
    #     - [–ë–∞–∑–∞ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤](main_table)
    #     - [–ö–ª—É–±—ã –∏ —Ä–µ–∫–æ—Ä–¥—ã](records_table)
    #     - [–ü–æ—á—Ç–∏ –≤ –∫–ª—É–±–µ](almost_club)
    #     - [–ö–∞–∫–∏–µ –ª—é–¥–∏!](hellothere)
    #     - [–ü–æ—Å–ª–µ–¥–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã](last_results)
    #     ''')

#####################################################################################################################################################
# –ü–∞—Ä—Å–∏–Ω–≥
#####################################################################################################################################################

main_url = 'https://5verst.ru/results/latest/'
tarjet_park = '–ü–µ—Ç–µ—Ä–≥–æ—Ñ'  # –ü–µ—Ç–µ—Ä–≥–æ—Ñ –ê–ª–µ–∫—Å–∞–Ω–¥—Ä–∏–π—Å–∫–∏–π
target_runs = [tarjet_park]

def get_last_date_from_site():
    url = 'https://5verst.ru/petergofaleksandriysky/results/all/'
    location_name = "petergof"
    
    try:
        # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è –∏–º–∏—Ç–∞—Ü–∏–∏ –±—Ä–∞—É–∑–µ—Ä–∞
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        response = requests.get(url, headers=headers, timeout=time_out)
        response.raise_for_status()  # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å –æ—Ç–≤–µ—Ç–∞
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # –ë–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω—ã–π –ø–æ–∏—Å–∫ —Ç–∞–±–ª–∏—Ü—ã
        tables = soup.find_all('table')
        if not tables:
            raise ValueError("–¢–∞–±–ª–∏—Ü—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ")

        # –ü–æ–ª—É—á–∞–µ–º —è—á–µ–π–∫–∏ –∏–∑ –≤—Ç–æ—Ä–æ–π —Å—Ç—Ä–æ–∫–∏
        run_data = []

        for row in tables[0].find_all('tr')[1:]:
            run_cells = row.find_all('td')
            number = run_cells[0].get_text(strip=True)
            date_cell = run_cells[1].get_text(strip=True)
            last_date_site = datetime.strptime(date_cell, '%d.%m.%Y').date()

            link = run_cells[1].find('a')['href'] if run_cells[1].find('a') else None
            finishers = int(run_cells[2].get_text(strip=True))
            volunteers = int(run_cells[3].get_text(strip=True))
            avg_time = run_cells[4].get_text(strip=True)
            best_female_time = run_cells[5].get_text(strip=True)
            best_male_time = run_cells[6].get_text(strip=True)
                
            if number:
                run_data.append([location_name, number, last_date_site, link, finishers, volunteers, avg_time, best_female_time, best_male_time])

        # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ last_date –∏–∑ —Ñ–æ—Ä–º–∞—Ç–∞ DD.MM.YYYY –≤ –æ–±—ä–µ–∫—Ç datetime
        moscow_tz = ZoneInfo('Europe/Moscow')
        now_t = datetime.now(moscow_tz).replace(microsecond=0, tzinfo=None)

        return run_data, now_t
        
    except requests.RequestException as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ —Å–∞–π—Ç—É: {e}")
        return None, None
    except ValueError as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
        return None, None
    except Exception as e:
        print(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
        return None, None


def parse_participant_and_volunteer_tables(run_protocol_link, run_data):
    '''get data from last protocol'''

    try:
        # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è –∏–º–∏—Ç–∞—Ü–∏–∏ –±—Ä–∞—É–∑–µ—Ä–∞
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        response = requests.get(run_protocol_link, headers=headers, timeout=time_out)
        response.raise_for_status()  # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å –æ—Ç–≤–µ—Ç–∞
        
        soup = BeautifulSoup(response.text, 'html.parser')
   
    except requests.RequestException as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ —Å–∞–π—Ç—É: {e}")
        return None, None
    
    all_tables = soup.find_all('table')

    # –ó–∞–±–µ–≥: location_name, number, date_cell, link, finishers, volunteers, avg_time, best_female_time, best_male_time
    location_name, number, date_cell, link, finishers, volunteer_count, avg_time, best_female_time, best_male_time = run_data

    participants_data = []
    volunteers_data = []

    # –ü–∞—Ä—Å–∏–º —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤
    participant_table = all_tables[0]
    for row in participant_table.find_all('tr')[1:]:
        cells = row.find_all('td')
        if len(cells) >= 4:
            position = cells[0].get_text(strip=True)
            name_tag = cells[1].find('a')
            name = name_tag.get_text(strip=True) if name_tag else '‚Äî'
            name_lc = name.lower()
            profile_link = name_tag['href'] if name_tag else '‚Äî'
            participant_id = profile_link.split('/')[-1] if profile_link != '‚Äî' else '‚Äî'
            stats_div = cells[1].find('div', class_='user-stat')
            finishes = '‚Äî'
            volunteers = '‚Äî'
            if stats_div:
                stats_spans = stats_div.find_all('span')
                finishes = stats_spans[0].get_text(strip=True).split(' ')[0] if len(stats_spans) > 0 else '‚Äî'
                volunteers = stats_spans[1].get_text(strip=True).split(' ')[0] if len(stats_spans) > 1 else '‚Äî'
            club_tags = cells[1].find_all('span', class_='club-icon')
            clubs = ', '.join([club['title'] for club in club_tags]) if club_tags else '‚Äî'
            age_group = cells[2].get_text(strip=True).split(' ')[0] if cells[2] else '‚Äî'
            age_grade_tag = cells[2].find('div', class_='age_grade')
            age_grade = age_grade_tag.get_text(strip=True) if age_grade_tag else '‚Äî'
            time = cells[3].get_text(strip=True) if cells[3] else '‚Äî'
            achievements = []
            achievements_div = cells[3].find('div', class_='table-achievments')
            if achievements_div:
                achievement_icons = achievements_div.find_all('span', class_='results_icon')
                for icon in achievement_icons:
                    achievements.append(icon['title'])
            participants_data.append([location_name, number, date_cell, link, finishers, volunteer_count, avg_time, best_female_time, best_male_time,
                                      position, name, name_lc, profile_link, participant_id, clubs, finishes, volunteers, age_group, age_grade, time, ', '.join(achievements)])
            
    # –ü–∞—Ä—Å–∏–º –≤–æ–ª–æ–Ω—Ç—ë—Ä–æ–≤
    volunteer_table = all_tables[1]
    for row in volunteer_table.find_all('tr')[1:]:
        columns = row.find_all('td')
        if len(columns) > 1:
            name_tag = columns[0].find('a')
            name = name_tag.get_text(strip=True) if name_tag else '‚Äî'
            name_lc = name.lower()
            profile_link = name_tag['href'] if name_tag else '‚Äî'
            participant_id = profile_link.split('/')[-1] if profile_link != '‚Äî' else '‚Äî'
            stats_div = columns[0].find('div', class_='user-stat')
            finishes = '‚Äî'
            volunteers = '‚Äî'
            if stats_div:
                stats_spans = stats_div.find_all('span')
                finishes = stats_spans[0].get_text(strip=True).split(' ')[0] if len(stats_spans) > 0 else '‚Äî'
                volunteers = stats_spans[1].get_text(strip=True).split(' ')[0] if len(stats_spans) > 1 else '‚Äî'
            club_tags = columns[0].find_all('span', class_='club-icon')
            clubs = ', '.join([club['title'] for club in club_tags]) if club_tags else '‚Äî'
            volunteer_role_info = columns[1].find('div', class_='volunteer__role')
            if volunteer_role_info:
                first_volunteer_tag = volunteer_role_info.find('span', class_='results_icon')
                first_volunteer_info = first_volunteer_tag['title'] if first_volunteer_tag else '‚Äî'
                role_tag = volunteer_role_info.find_all('span')
                volunteer_role = role_tag[-1].get_text(strip=True) if role_tag else '‚Äî'
            else:
                first_volunteer_info = '‚Äî'
                volunteer_role = '‚Äî'
            volunteers_data.append([location_name, number, date_cell, link, finishers, volunteer_count, avg_time, best_female_time, best_male_time,
                                    name, name_lc, profile_link, participant_id, finishes, volunteers, clubs, volunteer_role, first_volunteer_info])
    
    return participants_data, volunteers_data

def get_full_run_data(run_data):
    '''Get runners and volonteers from several protocols'''
    all_participant_data = []
    all_volunteer_data = []

    for run_dat in run_data[:num_runs]:
        participants, volunteers = parse_participant_and_volunteer_tables(run_dat[3], run_dat)
    
        all_participant_data.extend(participants)
        all_volunteer_data.extend(volunteers)

    return all_participant_data, all_volunteer_data

def save_to_database(df_runners, df_orgs, db_url):
    # –°–æ–∑–¥–∞–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
    print(db_url)
    engine = create_engine(db_url)
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –±–µ–≥—É–Ω–æ–≤ –≤ —Ç–∞–±–ª–∏—Ü—É 'runners'
    df_runners.to_sql('runners', con=engine, if_exists='replace', index=False)
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ç–æ—Ä–æ–≤ –≤ —Ç–∞–±–ª–∏—Ü—É 'organizers'
    df_orgs.to_sql('organizers', con=engine, if_exists='replace', index=False)


def update_data(all_participant_data, all_volunteer_data, db_name):
    # –°–æ–∑–¥–∞—ë–º DataFrame –¥–ª—è –±–µ–≥—É–Ω–æ–≤
    df_runners = pd.DataFrame(all_participant_data, columns=[
        'run', 'run_number', 'run_date', 'run_link', 'finisher', 'volunteer', 'avg_time',
        'best_female_time', 'best_male_time', 'position', 'name', 'name_lc', 'profile_link',
        'participant_id', 'clubs', 'finishes', 'volunteers', 'age_group', 'age_grade',
        'time', 'achievements'
    ])
    df_runners['run_date'] = pd.to_datetime(df_runners['run_date'], dayfirst=True)

    # –°–æ–∑–¥–∞—ë–º DataFrame –¥–ª—è –≤–æ–ª–æ–Ω—Ç—ë—Ä–æ–≤
    df_orgs = pd.DataFrame(all_volunteer_data, columns=[
        'run', 'run_number', 'run_date', 'run_link', 'finisher', 'volunteer', 'avg_time',
        'best_female_time', 'best_male_time', 'name', 'name_lc', 'profile_link', 'participant_id',
        'finishes', 'volunteers', 'clubs', 'volunteer_role', 'first_volunteer_info'
    ])
    df_orgs['run_date'] = pd.to_datetime(df_orgs['run_date'], dayfirst=True)

    save_to_database(df_runners, df_orgs, db_name)


def get_last_date_from_db(db_url):
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
    db_path = db_url.replace('sqlite:///', '')
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —Ñ–∞–π–ª –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
    if not os.path.exists(db_path):
        return None, None  # –ï—Å–ª–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º None
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞—Ç—É –∏ –≤—Ä–µ–º—è –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞
    filename = os.path.basename(db_path)
    time_db = convert_date_string(filename[:-3])
    
    try:
        # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö, –µ—Å–ª–∏ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        # st.write(db_url)
        engine = create_engine(db_url)
        with engine.connect() as connection:
            st.write('connected')
            query = text("SELECT MAX(run_date) FROM runners;")  # –ó–∞–º–µ–Ω–∏—Ç—å run_date –Ω–∞ —Ä–µ–∞–ª—å–Ω–æ–µ –∏–º—è –∫–æ–ª–æ–Ω–∫–∏ —Å –¥–∞—Ç–æ–π
            result = connection.execute(query)
            last_date_db = result.scalar()

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å–ª–∏ last_date_db –Ω–µ None, —Ç–æ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å—Ç—Ä–æ–∫—É –≤ –¥–∞—Ç—É
            if last_date_db:
                last_date_db = datetime.strptime(last_date_db, '%Y-%m-%d %H:%M:%S.%f').date()
            else:
                last_date_db = None
    except Exception as e:
        st.write(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")
        return None, time_db
    
    return last_date_db, time_db

# def extract_datetime_from_filename(filename):
#     """
#     –ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞—Ç—É –∏ –≤—Ä–µ–º—è –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY_MM_DD_HH_MM_SS.db
#     """
#     # –†–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø–æ–∏—Å–∫–∞ —à–∞–±–ª–æ–Ω–∞ –¥–∞—Ç—ã –∏ –≤—Ä–µ–º–µ–Ω–∏
#     pattern = r'(\d{4})_(\d{2})_(\d{2})_(\d{2})_(\d{2})_(\d{2})\.db$'
#     match = re.search(pattern, filename)
    
#     if match:
#         year, month, day, hour, minute, second = map(int, match.groups())
#         try:
#             time_db = datetime(year, month, day, hour, minute, second)
#             st.write(time_db)
#             return time_db
#         except ValueError:
#             st.write('Incorrect data')
#             # –ï—Å–ª–∏ –¥–∞—Ç–∞ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 2023_02_30_25_61_61.db)
#             return None
    
#     return None  # –ï—Å–ª–∏ —à–∞–±–ª–æ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω


def keep_only_latest_db_by_mtime():
    """
    –û—Å—Ç–∞–≤–ª—è–µ—Ç —Å–∞–º—É—é —Å–≤–µ–∂—É—é –ë–î –ø–æ –¥–∞—Ç–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–∞
    """
    db_files = glob.glob(os.path.join('*.db'))
    
    if not db_files:
        print("–ë–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return None
    
    if len(db_files) == 1:
        print(f"–¢–æ–ª—å–∫–æ –æ–¥–Ω–∞ –ë–î: {os.path.basename(db_files[0])}")
        return db_files[0]
    
    # –ù–∞—Ö–æ–¥–∏–º —Å–∞–º—É—é —Å–≤–µ–∂—É—é –ø–æ –¥–∞—Ç–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
    latest_db = max(db_files, key=os.path.getmtime)
    
    print(f"–°–æ—Ö—Ä–∞–Ω—è–µ–º: {os.path.basename(latest_db)}")
    print(f"–£–¥–∞–ª—è–µ–º {len(db_files) - 1} —Ñ–∞–π–ª–æ–≤:")
    
    for db_file in db_files:
        if db_file != latest_db:
            try:
                os.remove(db_file)
                print(f"  ‚úì –£–¥–∞–ª–µ–Ω–æ: {os.path.basename(db_file)}")
            except Exception as e:
                print(f"  ‚úó –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ {db_file}: {e}")
    
    return latest_db

if username in ['host']:
    with col2:
        st.write('*–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ë–î:*')
        if st.button('–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ —Å —Å–∞–π—Ç–∞'):
            try:
                run_data, now_t = get_last_date_from_site()
                if run_data:
                    ss['run_data'] = run_data
                    ss['now_t'] = now_t
                    st.subheader(f'–ü—Ä–æ—Ç–æ–∫–æ–ª—ã —Å –æ—Ñ. —Å–∞–π—Ç–∞ –Ω–∞ {now_t}')  
                    for run_dat in run_data[:num_runs]:
                        location_name, number, date_cell, link, finishers, volunteers, avg_time, best_female_time, best_male_time = run_dat
                        st.markdown(f'''[#{number} {date_cell}]({link}), {finishers} —Ñ–∏–Ω. {volunteers} –≤–æ–ª.''')
                    st.success('–°–ø–∏—Å–∫–∏ –ø–æ–ª—É—á–µ–Ω—ã')
            except Exception as e:
                st.write(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
        # last_date_db = get_last_date_from_db()
            
        # with col2:
        if st.button('–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ'):
            if run_data:
                # st.subheader(f'–ê–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö –Ω–∞ {now_t}')  
                for run_dat in run_data[:num_runs]:
                    location_name, number, date_cell, link, finishers, volunteers, avg_time, best_female_time, best_male_time = run_dat
                    # st.markdown(f'''[#{number} {date_cell}]({link}), {finishers} —Ñ–∏–Ω. {volunteers} –≤–æ–ª.''')
                
                try:
                    all_participant_data, all_volunteer_data = get_full_run_data(run_data)
                    ss['all_participant_data'] = all_participant_data
                    ss['all_volunteer_data'] = all_volunteer_data
                    st.success('–ü—Ä–æ—Ç–æ–∫–æ–ª—ã –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã')
                except Exception as e:
                    st.write(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")

                # st.markdown(f'''{all_participant_data[0]} {all_volunteer_data[0]}''')
                # st.markdown(f'''{len(all_participant_data)} {len(all_volunteer_data)} {len(run_data)}''')
            else:
                st.write('–ü—Ä–æ—Ç–æ–∫–æ–ª—ã —Å —Å–∞–π—Ç–∞ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã')

        if st.button('–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ –±–∞–∑—É'):
            if all_participant_data and all_volunteer_data and now_t:
                print(now_t)
                db_name = 'sqlite:///' + now_t.strftime("%Y_%m_%d_%H_%M_%S.db")
                print(db_name)
                update_data(all_participant_data, all_volunteer_data, db_name)
                keep_only_latest_db_by_mtime()
                st.success('–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ –±–∞–∑—É')
            else: 
                st.write('–î–∞–Ω–Ω—ã–µ –Ω–µ –ø–æ–ª—É—á–µ–Ω—ã')

        if st.button('–ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∞–∑—ã'):
            # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
            db_name = find_db_files()
            if db_name:
                db_name = 'sqlite:///' + db_name[-1]
                engine = create_engine(db_name)
                st.success(f'–ù–∞–π–¥–µ–Ω–∞ –ë–î –æ—Ç {convert_date_string(db_name[10:-3])}')
            else:
                st.write('–ë–∞–∑–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')
            # last_date_db, time_db = get_last_date_from_db(db_name)